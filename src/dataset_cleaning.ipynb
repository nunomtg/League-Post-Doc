{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from polars import col\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'dataset\\\\2023_LoL_esports_match_data_from_OraclesElixir.csv'\n",
    "COLUMNS_NEEDED = ['gameid', 'league', 'side', 'position', 'champion', 'result']\n",
    "COLUMNS_TYPES = {\n",
    "    'gameid': pl.Utf8,\n",
    "    'league': pl.Utf8,\n",
    "    'side': pl.Utf8,\n",
    "    'position': pl.Utf8,\n",
    "    'champion': pl.Utf8,\n",
    "    'result': pl.Int8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\n",
    "            source=PATH,\n",
    "            has_header=True,\n",
    "            columns=COLUMNS_NEEDED,\n",
    "            dtypes=COLUMNS_TYPES\n",
    "            ).drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df['gameid'].n_unique() == df.shape[0] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_CHAMPIONS = df['champion'].unique().to_list()\n",
    "\n",
    "CHAMP_TO_IDX = {champ: idx for idx, champ in enumerate(LIST_OF_CHAMPIONS)}\n",
    "\n",
    "# Add the 'champion_idx' column\n",
    "df = df.with_columns\\\n",
    "    (\n",
    "    pl.col('champion') \\\n",
    "    .apply(lambda x: CHAMP_TO_IDX.get(x, x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'gameid' and 'side', collect champion indices for each game and side\n",
    "df = df.groupby(['gameid', 'league', 'side' ,'result']).agg(\n",
    "    pl.col('champion').apply(list).alias('champions')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into two based on 'side'\n",
    "df_blue = df.filter(df['side'] == 'Blue').drop('side').rename({'champions': 'Blue_champions'})\n",
    "df_red = df.filter(df['side'] == 'Red').drop('side').rename({'champions': 'Red_champions'})\n",
    "\n",
    "df_blue = df_blue.with_columns\\\n",
    "    (\n",
    "    pl.col('result').apply(lambda x: \"Blue\" if x == 1 else \"Red\").alias('result')\n",
    "    )\n",
    "\n",
    "df_red = df_red.with_columns\\\n",
    "    (\n",
    "    pl.col('result').apply(lambda x: \"Red\" if x == 1 else \"Blue\").alias('result')\n",
    "    )\n",
    "\n",
    "assert (df_blue.sort(by=\"gameid\")[\"result\"]).eq(df_red.sort(by=\"gameid\")[\"result\"]).all()\n",
    "\n",
    "# Join the two dataframes on 'gameid'\n",
    "df = df_blue.join(df_red, on=['gameid', 'league', 'result'])\n",
    "\n",
    "# Create new column where we have the result as a number (1 if Blue won, 0 if Red won)\n",
    "df = df.with_columns\\\n",
    "    (\n",
    "    pl.col('result').apply(lambda x: 1 if x == \"Blue\" else 0).alias('result_binary')\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(fraction=1, shuffle=True)\n",
    "test_size = 20 * df.shape[0] // 100\n",
    "test, train = df.head(test_size), df.tail(-test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_champions_list_train = train['Blue_champions'].to_list()\n",
    "red_champions_list_train = train['Red_champions'].to_list()\n",
    "result_list_train = train['result_binary'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_champions_list_test = test['Blue_champions'].to_list()\n",
    "red_champions_list_test = test['Red_champions'].to_list()\n",
    "result_list_test = test['result_binary'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(blue_champions_list_train), f=\"dataset\\\\blue_champions_train.pt\")\n",
    "torch.save(torch.tensor(red_champions_list_train), f=\"dataset\\\\red_champions_train.pt\")\n",
    "torch.save(torch.tensor(result_list_train), f=\"dataset\\\\result_train.pt\")\n",
    "\n",
    "torch.save(torch.tensor(blue_champions_list_test), f=\"dataset\\\\blue_champions_test.pt\")\n",
    "torch.save(torch.tensor(red_champions_list_test), f=\"dataset\\\\red_champions_test.pt\")\n",
    "torch.save(torch.tensor(result_list_test), f=\"dataset\\\\result_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['dataset_cleaning'])\n",
    "import dataset_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset_cleaning.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LeagueOfLegendsDataset(Dataset):\n",
    "    def __init__(self, type=\"train\"):\n",
    "        \n",
    "        assert type in [\"train\", \"test\"]\n",
    "        \n",
    "        self.blue_champions = torch.load(f=f\"dataset\\\\blue_champions_{type}.pt\")\n",
    "        self.red_champions = torch.load(f=f\"dataset\\\\red_champions_{type}.pt\")\n",
    "        self.result = torch.load(f=f\"dataset\\\\result_{type}.pt\")\n",
    "        print(\"Dataset loaded\")\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.blue_champions) == len(self.red_champions) == len(self.result)\n",
    "        return len(self.blue_champions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.blue_champions[idx], self.red_champions[idx], self.result[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_train = LeagueOfLegendsDataset(type=\"train\")\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "dataset_test = LeagueOfLegendsDataset(type=\"test\")\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6226, 1556)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader_train), len(data_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 20,  50, 112,  96, 104]]), tensor([[ 58,  19,  41, 141,   9]]), tensor([1])]\n"
     ]
    }
   ],
   "source": [
    "for i in data_loader_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
